nohup: 忽略输入
Creating Global Linear Model with 31 tags
Using 803 sentences to create the feature space
The size of the feature space is 81541
Using online-training algorithm to train the model
Epoch 0 / 100: 
	train: 19257 / 20454 = 0.941478
	dev: 42616 / 50319 = 0.846917
	514.330973s elapsed
Epoch 1 / 100: 
	train: 19899 / 20454 = 0.972866
	dev: 43485 / 50319 = 0.864186
	506.547944s elapsed
Epoch 2 / 100: 
	train: 20100 / 20454 = 0.982693
	dev: 43805 / 50319 = 0.870546
	507.300984s elapsed
Epoch 3 / 100: 
	train: 20204 / 20454 = 0.987777
	dev: 43942 / 50319 = 0.873269
	512.582841s elapsed
Epoch 4 / 100: 
	train: 20259 / 20454 = 0.990466
	dev: 43998 / 50319 = 0.874381
	515.973759s elapsed
Epoch 5 / 100: 
	train: 20298 / 20454 = 0.992373
	dev: 43991 / 50319 = 0.874242
	515.146832s elapsed
Epoch 6 / 100: 
	train: 20324 / 20454 = 0.993644
	dev: 44040 / 50319 = 0.875216
	513.815494s elapsed
Epoch 7 / 100: 
	train: 20343 / 20454 = 0.994573
	dev: 44061 / 50319 = 0.875633
	513.631572s elapsed
Epoch 8 / 100: 
	train: 20360 / 20454 = 0.995404
	dev: 44076 / 50319 = 0.875932
	513.396404s elapsed
Epoch 9 / 100: 
	train: 20366 / 20454 = 0.995698
	dev: 44086 / 50319 = 0.876130
	513.864900s elapsed
Epoch 10 / 100: 
	train: 20373 / 20454 = 0.996040
	dev: 44092 / 50319 = 0.876250
	515.115810s elapsed
Epoch 11 / 100: 
	train: 20383 / 20454 = 0.996529
	dev: 44107 / 50319 = 0.876548
	514.331215s elapsed
Epoch 12 / 100: 
	train: 20386 / 20454 = 0.996675
	dev: 44112 / 50319 = 0.876647
	514.935175s elapsed
Epoch 13 / 100: 
	train: 20386 / 20454 = 0.996675
	dev: 44111 / 50319 = 0.876627
	513.899599s elapsed
Epoch 14 / 100: 
	train: 20387 / 20454 = 0.996724
	dev: 44112 / 50319 = 0.876647
	513.181306s elapsed
Epoch 15 / 100: 
	train: 20390 / 20454 = 0.996871
	dev: 44119 / 50319 = 0.876786
	514.193172s elapsed
Epoch 16 / 100: 
	train: 20390 / 20454 = 0.996871
	dev: 44119 / 50319 = 0.876786
	513.327039s elapsed
Epoch 17 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44119 / 50319 = 0.876786
	514.336667s elapsed
Epoch 18 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44119 / 50319 = 0.876786
	512.849586s elapsed
Epoch 19 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44130 / 50319 = 0.877005
	513.041255s elapsed
Epoch 20 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44128 / 50319 = 0.876965
	508.381319s elapsed
Epoch 21 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44128 / 50319 = 0.876965
	531.113647s elapsed
Epoch 22 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44128 / 50319 = 0.876965
	540.307889s elapsed
Epoch 23 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44128 / 50319 = 0.876965
	538.389787s elapsed
Epoch 24 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44128 / 50319 = 0.876965
	537.163164s elapsed
Epoch 25 / 100: 
	train: 20391 / 20454 = 0.996920
	dev: 44128 / 50319 = 0.876965
	531.924749s elapsed
max precision of dev is 0.877005 at epoch 19
13454.770436s elapsed

nohup: 忽略输入
Creating Global Linear Model with 35 tags
Using 46572 sentences to create the feature space
The size of the feature space is 1688542
Using online-training algorithm to train the model
Epoch 0 / 100: 
	train: 1006534 / 1057943 = 0.951407
	dev: 55933 / 59955 = 0.932916
	18325.217528s elapsed
Epoch 1 / 100: 
	train: 1018207 / 1057943 = 0.962440
	dev: 56174 / 59955 = 0.936936
	18137.796634s elapsed
Epoch 2 / 100: 
	train: 1024576 / 1057943 = 0.968460
	dev: 56299 / 59955 = 0.939021
	17812.604389s elapsed
Epoch 3 / 100: 
	train: 1028981 / 1057943 = 0.972624
	dev: 56384 / 59955 = 0.940439
	17773.644670s elapsed
Epoch 4 / 100: 
	train: 1032373 / 1057943 = 0.975830
	dev: 56431 / 59955 = 0.941223
	17994.049446s elapsed
Epoch 5 / 100: 
	train: 1034979 / 1057943 = 0.978294
	dev: 56440 / 59955 = 0.941373
	18189.687231s elapsed
Epoch 6 / 100: 
	train: 1037047 / 1057943 = 0.980248
	dev: 56446 / 59955 = 0.941473
	18180.033285s elapsed
Epoch 7 / 100: 
	train: 1038808 / 1057943 = 0.981913
	dev: 56477 / 59955 = 0.941990
	18292.619897s elapsed
Epoch 8 / 100: 
	train: 1040338 / 1057943 = 0.983359
	dev: 56486 / 59955 = 0.942140
	18462.280476s elapsed
Epoch 9 / 100: 
	train: 1041610 / 1057943 = 0.984562
	dev: 56474 / 59955 = 0.941940
	18032.447692s elapsed
Epoch 10 / 100: 
	train: 1042645 / 1057943 = 0.985540
	dev: 56481 / 59955 = 0.942057
	17703.759253s elapsed
Epoch 11 / 100: 
	train: 1043522 / 1057943 = 0.986369
	dev: 56486 / 59955 = 0.942140
	17775.305570s elapsed
Epoch 12 / 100: 
	train: 1044373 / 1057943 = 0.987173
	dev: 56488 / 59955 = 0.942173
	18097.833639s elapsed
Epoch 13 / 100: 
	train: 1045094 / 1057943 = 0.987855
	dev: 56484 / 59955 = 0.942107
	18070.080094s elapsed
Epoch 14 / 100: 
	train: 1045754 / 1057943 = 0.988479
	dev: 56490 / 59955 = 0.942207
	18127.171998s elapsed
Epoch 15 / 100: 
	train: 1046363 / 1057943 = 0.989054
	dev: 56491 / 59955 = 0.942223
	18112.733961s elapsed
Epoch 16 / 100: 
	train: 1046873 / 1057943 = 0.989536
	dev: 56474 / 59955 = 0.941940
	17784.757574s elapsed
Epoch 17 / 100: 
	train: 1047352 / 1057943 = 0.989989
	dev: 56478 / 59955 = 0.942007
	17907.944918s elapsed
Epoch 18 / 100: 
	train: 1047709 / 1057943 = 0.990327
	dev: 56476 / 59955 = 0.941973
	18147.568493s elapsed
Epoch 19 / 100: 
	train: 1048089 / 1057943 = 0.990686
	dev: 56478 / 59955 = 0.942007
	18219.973710s elapsed
Epoch 20 / 100: 
	train: 1048451 / 1057943 = 0.991028
	dev: 56477 / 59955 = 0.941990
	18091.885782s elapsed
Epoch 21 / 100: 
	train: 1048759 / 1057943 = 0.991319
	dev: 56475 / 59955 = 0.941956
	18151.147076s elapsed
Epoch 22 / 100: 
	train: 1049050 / 1057943 = 0.991594
	dev: 56477 / 59955 = 0.941990
	18221.092039s elapsed
Epoch 23 / 100: 
	train: 1049305 / 1057943 = 0.991835
	dev: 56473 / 59955 = 0.941923
	18048.831657s elapsed
Epoch 24 / 100: 
	train: 1049551 / 1057943 = 0.992068
	dev: 56465 / 59955 = 0.941790
	18119.483990s elapsed
Epoch 25 / 100: 
	train: 1049796 / 1057943 = 0.992299
	dev: 56466 / 59955 = 0.941806
	17879.782261s elapsed
Epoch 26 / 100: 
	train: 1049998 / 1057943 = 0.992490
	dev: 56473 / 59955 = 0.941923
	17744.274558s elapsed
max precision of dev is 0.942223 at epoch 15
Precision of test: 75807 / 81578 = 0.929258
488158.716056s elapsed

