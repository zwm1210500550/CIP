Preprocessing the data
Creating Global Linear Model with 31 tags
	use feature extracion optimization
Using 803 sentences to create the feature space
The size of the feature space is 67391
Using online-training algorithm to train the model
Epoch 0 / 100:
	train: 18712 / 20454 = 0.914833
	dev: 41048 / 50319 = 0.815755
	0:00:06.388631s elapsed
Epoch 1 / 100:
	train: 19553 / 20454 = 0.955950
	dev: 41882 / 50319 = 0.832330
	0:00:06.077317s elapsed
Epoch 2 / 100:
	train: 20060 / 20454 = 0.980737
	dev: 43096 / 50319 = 0.856456
	0:00:05.754685s elapsed
Epoch 3 / 100:
	train: 20276 / 20454 = 0.991298
	dev: 43681 / 50319 = 0.868082
	0:00:05.302059s elapsed
Epoch 4 / 100:
	train: 20271 / 20454 = 0.991053
	dev: 43425 / 50319 = 0.862994
	0:00:05.102489s elapsed
Epoch 5 / 100:
	train: 20248 / 20454 = 0.989929
	dev: 43487 / 50319 = 0.864226
	0:00:04.996067s elapsed
Epoch 6 / 100:
	train: 20360 / 20454 = 0.995404
	dev: 43703 / 50319 = 0.868519
	0:00:04.682566s elapsed
Epoch 7 / 100:
	train: 20341 / 20454 = 0.994475
	dev: 43726 / 50319 = 0.868976
	0:00:04.932632s elapsed
Epoch 8 / 100:
	train: 20366 / 20454 = 0.995698
	dev: 43718 / 50319 = 0.868817
	0:00:05.092726s elapsed
Epoch 9 / 100:
	train: 20407 / 20454 = 0.997702
	dev: 43798 / 50319 = 0.870407
	0:00:04.521770s elapsed
Epoch 10 / 100:
	train: 20441 / 20454 = 0.999364
	dev: 43905 / 50319 = 0.872533
	0:00:04.795115s elapsed
Epoch 11 / 100:
	train: 20426 / 20454 = 0.998631
	dev: 43790 / 50319 = 0.870248
	0:00:04.606238s elapsed
Epoch 12 / 100:
	train: 20434 / 20454 = 0.999022
	dev: 43784 / 50319 = 0.870129
	0:00:04.323061s elapsed
Epoch 13 / 100:
	train: 20427 / 20454 = 0.998680
	dev: 43726 / 50319 = 0.868976
	0:00:04.486196s elapsed
Epoch 14 / 100:
	train: 20436 / 20454 = 0.999120
	dev: 43937 / 50319 = 0.873169
	0:00:04.475772s elapsed
Epoch 15 / 100:
	train: 20451 / 20454 = 0.999853
	dev: 43862 / 50319 = 0.871679
	0:00:04.618476s elapsed
Epoch 16 / 100:
	train: 20450 / 20454 = 0.999804
	dev: 43844 / 50319 = 0.871321
	0:00:04.337390s elapsed
Epoch 17 / 100:
	train: 20440 / 20454 = 0.999316
	dev: 43695 / 50319 = 0.868360
	0:00:04.319077s elapsed
Epoch 18 / 100:
	train: 20441 / 20454 = 0.999364
	dev: 43803 / 50319 = 0.870506
	0:00:04.419217s elapsed
Epoch 19 / 100:
	train: 20430 / 20454 = 0.998827
	dev: 43749 / 50319 = 0.869433
	0:00:04.519245s elapsed
Epoch 20 / 100:
	train: 20448 / 20454 = 0.999707
	dev: 43891 / 50319 = 0.872255
	0:00:04.354792s elapsed
max precision of dev is 0.873169 at epoch 14
mean time of each epoch is 0:00:04.862168s
0:01:43.414547s elapsed

Preprocessing the data
Creating Global Linear Model with 35 tags
	use feature extracion optimization
Using 46572 sentences to create the feature space
The size of the feature space is 1400228
Using online-training algorithm to train the model
Epoch 0 / 100:
	train: 978113 / 1057943 = 0.924542
	dev: 53837 / 59955 = 0.897957
	0:03:33.028451s elapsed
Epoch 1 / 100:
	train: 998652 / 1057943 = 0.943956
	dev: 54591 / 59955 = 0.910533
	0:03:22.211506s elapsed
Epoch 2 / 100:
	train: 1006852 / 1057943 = 0.951707
	dev: 54851 / 59955 = 0.914869
	0:03:13.028605s elapsed
Epoch 3 / 100:
	train: 1012676 / 1057943 = 0.957212
	dev: 55100 / 59955 = 0.919023
	0:03:05.302475s elapsed
Epoch 4 / 100:
	train: 1018116 / 1057943 = 0.962354
	dev: 55156 / 59955 = 0.919957
	0:02:57.151678s elapsed
Epoch 5 / 100:
	train: 1018529 / 1057943 = 0.962745
	dev: 55079 / 59955 = 0.918672
	0:02:54.023695s elapsed
Epoch 6 / 100:
	train: 1026167 / 1057943 = 0.969964
	dev: 55404 / 59955 = 0.924093
	0:02:49.120755s elapsed
Epoch 7 / 100:
	train: 1026038 / 1057943 = 0.969842
	dev: 55430 / 59955 = 0.924527
	0:02:44.516169s elapsed
Epoch 8 / 100:
	train: 1028080 / 1057943 = 0.971773
	dev: 55399 / 59955 = 0.924010
	0:02:43.557663s elapsed
Epoch 9 / 100:
	train: 1030136 / 1057943 = 0.973716
	dev: 55513 / 59955 = 0.925911
	0:02:41.011132s elapsed
Epoch 10 / 100:
	train: 1028310 / 1057943 = 0.971990
	dev: 55555 / 59955 = 0.926612
	0:02:37.787808s elapsed
Epoch 11 / 100:
	train: 1032152 / 1057943 = 0.975622
	dev: 55530 / 59955 = 0.926195
	0:02:35.011844s elapsed
Epoch 12 / 100:
	train: 1032038 / 1057943 = 0.975514
	dev: 55446 / 59955 = 0.924794
	0:02:32.800134s elapsed
Epoch 13 / 100:
	train: 1033852 / 1057943 = 0.977228
	dev: 55623 / 59955 = 0.927746
	0:02:36.068106s elapsed
Epoch 14 / 100:
	train: 1032878 / 1057943 = 0.976308
	dev: 55552 / 59955 = 0.926562
	0:02:43.763225s elapsed
Epoch 15 / 100:
	train: 1033749 / 1057943 = 0.977131
	dev: 55587 / 59955 = 0.927145
	0:02:34.670365s elapsed
Epoch 16 / 100:
	train: 1035831 / 1057943 = 0.979099
	dev: 55728 / 59955 = 0.929497
	0:02:32.997668s elapsed
Epoch 17 / 100:
	train: 1035639 / 1057943 = 0.978918
	dev: 55762 / 59955 = 0.930064
	0:02:32.079226s elapsed
Epoch 18 / 100:
	train: 1036610 / 1057943 = 0.979835
	dev: 55783 / 59955 = 0.930414
	0:02:28.313035s elapsed
Epoch 19 / 100:
	train: 1035863 / 1057943 = 0.979129
	dev: 55789 / 59955 = 0.930515
	0:02:27.993399s elapsed
Epoch 20 / 100:
	train: 1037594 / 1057943 = 0.980766
	dev: 55774 / 59955 = 0.930264
	0:02:29.523104s elapsed
Epoch 21 / 100:
	train: 1037675 / 1057943 = 0.980842
	dev: 55763 / 59955 = 0.930081
	0:02:27.935712s elapsed
Epoch 22 / 100:
	train: 1037957 / 1057943 = 0.981109
	dev: 55637 / 59955 = 0.927979
	0:02:27.281468s elapsed
Epoch 23 / 100:
	train: 1039096 / 1057943 = 0.982185
	dev: 55769 / 59955 = 0.930181
	0:02:26.473317s elapsed
Epoch 24 / 100:
	train: 1039089 / 1057943 = 0.982179
	dev: 55853 / 59955 = 0.931582
	0:02:26.276352s elapsed
Epoch 25 / 100:
	train: 1038971 / 1057943 = 0.982067
	dev: 55846 / 59955 = 0.931465
	0:02:23.856768s elapsed
Epoch 26 / 100:
	train: 1039353 / 1057943 = 0.982428
	dev: 55868 / 59955 = 0.931832
	0:02:22.072281s elapsed
Epoch 27 / 100:
	train: 1039447 / 1057943 = 0.982517
	dev: 55863 / 59955 = 0.931749
	0:02:22.350562s elapsed
Epoch 28 / 100:
	train: 1038162 / 1057943 = 0.981302
	dev: 55665 / 59955 = 0.928446
	0:02:21.921717s elapsed
Epoch 29 / 100:
	train: 1039086 / 1057943 = 0.982176
	dev: 55765 / 59955 = 0.930114
	0:02:21.841590s elapsed
Epoch 30 / 100:
	train: 1038598 / 1057943 = 0.981715
	dev: 55741 / 59955 = 0.929714
	0:02:21.098067s elapsed
Epoch 31 / 100:
	train: 1038874 / 1057943 = 0.981975
	dev: 55839 / 59955 = 0.931349
	0:02:19.920542s elapsed
Epoch 32 / 100:
	train: 1039708 / 1057943 = 0.982764
	dev: 55805 / 59955 = 0.930781
	0:02:19.544590s elapsed
Epoch 33 / 100:
	train: 1040396 / 1057943 = 0.983414
	dev: 55821 / 59955 = 0.931048
	0:02:19.599850s elapsed
Epoch 34 / 100:
	train: 1039013 / 1057943 = 0.982107
	dev: 55784 / 59955 = 0.930431
	0:02:19.674411s elapsed
Epoch 35 / 100:
	train: 1039829 / 1057943 = 0.982878
	dev: 55820 / 59955 = 0.931032
	0:02:19.841404s elapsed
Epoch 36 / 100:
	train: 1040745 / 1057943 = 0.983744
	dev: 55907 / 59955 = 0.932483
	0:02:21.281676s elapsed
Epoch 37 / 100:
	train: 1039900 / 1057943 = 0.982945
	dev: 55735 / 59955 = 0.929614
	0:02:22.850952s elapsed
Epoch 38 / 100:
	train: 1039303 / 1057943 = 0.982381
	dev: 55749 / 59955 = 0.929847
	0:02:22.308027s elapsed
Epoch 39 / 100:
	train: 1039911 / 1057943 = 0.982956
	dev: 55747 / 59955 = 0.929814
	0:02:20.343948s elapsed
Epoch 40 / 100:
	train: 1040769 / 1057943 = 0.983767
	dev: 55834 / 59955 = 0.931265
	0:02:23.536288s elapsed
Epoch 41 / 100:
	train: 1040093 / 1057943 = 0.983128
	dev: 55822 / 59955 = 0.931065
	0:02:23.804571s elapsed
Epoch 42 / 100:
	train: 1039820 / 1057943 = 0.982870
	dev: 55892 / 59955 = 0.932233
	0:02:23.373851s elapsed
Epoch 43 / 100:
	train: 1039338 / 1057943 = 0.982414
	dev: 55806 / 59955 = 0.930798
	0:02:24.775967s elapsed
Epoch 44 / 100:
	train: 1041816 / 1057943 = 0.984756
	dev: 55801 / 59955 = 0.930715
	0:02:23.384844s elapsed
Epoch 45 / 100:
	train: 1041062 / 1057943 = 0.984044
	dev: 55791 / 59955 = 0.930548
	0:02:23.446927s elapsed
Epoch 46 / 100:
	train: 1040680 / 1057943 = 0.983682
	dev: 55854 / 59955 = 0.931599
	0:02:22.815356s elapsed
Epoch 47 / 100:
	train: 1040656 / 1057943 = 0.983660
	dev: 55829 / 59955 = 0.931182
	0:02:20.964634s elapsed
max precision of dev is 0.932483 at epoch 36
mean time of each epoch is 0:02:33.052827s
Precision of test: 75843 / 81578 = 0.929699
2:03:47.383786s elapsed

